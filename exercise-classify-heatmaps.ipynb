{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification of Heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Introduction](#Introduction)\n",
    "* [Requirements](#Requirements) \n",
    "  * [Modules](#Python-Modules)\n",
    "* [Exercises](#Exercises)\n",
    " * [Load the Data](#Load-the-Data)\n",
    " * [Prepare the Data](#Prepare-the-Data)\n",
    " * [Remove Invalid Values](#Remove-Invalid-Values)\n",
    " * [Train and Visualize Simple Decission Tree](#Train-and-Visualize-Simple-Decission-Tree)\n",
    " * [Save as CSV](#Save-as-CSV)\n",
    "* [Summary and Outlook](#Summary-and-Outlook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the last notebook we extracted geometrical features from our heatmaps and saved them in csv files. Now we will use these features to train a simple classifier to predict the lables of the slides (_negative, itc, micro, macro_).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "### Python-Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn import tree, naive_bayes, ensemble\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from graphviz import Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Before we start, adjust the path of `CAM_BASE_DIR` (and also other variables as needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "### EDIT THIS CELL:\n",
    "### Do not edit this cell\n",
    "### Assign the path to your CAMELYON16 data and create the directories\n",
    "### if they do not exist yet.\n",
    "CAM_BASE_DIR = '/path/to/CAMELYON/data/'\n",
    "\n",
    "# exmple:\n",
    "CAM_BASE_DIR = '/media/klaus/2612FE3171F55111/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATED_DATA = CAM_BASE_DIR + 'tutorial/' \n",
    "HEATMAP_DIR = CAM_BASE_DIR + 'c16traintest_c17traintest_heatmaps_grey/'\n",
    "\n",
    "# CAMELYON16 and 17 ground truth labels\n",
    "PATH_C16_LABELS = CAM_BASE_DIR + 'CAMELYON16/test/Ground_Truth/reference.csv'\n",
    "PATH_C17_LABELS = CAM_BASE_DIR + 'CAMELYON17/training/stage_labels.csv'\n",
    "\n",
    "FEATURES_C16TEST = GENERATED_DATA + 'features_c16_test.csv'\n",
    "FEATURES_C17TRAIN = GENERATED_DATA +'features_c17_train.csv'\n",
    "FEATURES_C17TEST = GENERATED_DATA +'features_c17_test.csv'\n",
    "\n",
    "# Here we will save our predictions\n",
    "PATH_C17TRAIN_PREDICITONS = CAM_BASE_DIR + 'CAMELYON17/c17_train_predictions.csv'\n",
    "PATH_C17TEST_PREDICITONS = CAM_BASE_DIR + 'CAMELYON17/c17_train_predictions.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data\n",
    "\n",
    "Now we read in the csv files as pandas `DataFrame` objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Data\n",
    "\n",
    "**Task:**\n",
    "\n",
    "Concatenate `c16_test` and `c17_train` in a new `DataFrame` variable `c1617_train`. That is the dataset we will use for hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1617_train = None ### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split the data into labels and features.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "- Load the `stage` column into a variable `y` (1D-numpy array)\n",
    "- Load the six features `highest_probability`, ... into a variable `x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise\n",
    "\n",
    "x = None # features\n",
    "y = None # labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Invalid Values\n",
    "\n",
    "Some heatmaps (~2 or 3) could not be created by the CNN, so values for some slides ar missing. \n",
    "\n",
    "**Task:**\n",
    "\n",
    "Replace the missing values using the `sklearn.preprocessing.Imputer` class.\n",
    "\n",
    "**Hint:**\n",
    "\n",
    "For better results look at the labels of the missing heatmaps and replace the values for the features with the label mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exercise\n",
    "\n",
    "# imp = \n",
    "# x = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Visualize Simple Decission Tree\n",
    "\n",
    "Now we are ready to define and train a decision tree.\n",
    "We use the [scikit learn decison tree module](http://scikit-learn.org/stable/modules/tree.html).\n",
    "\n",
    "**Task:**\n",
    "\n",
    "- Define and train a decision tree for visualization first\n",
    "- Define and train a decision tree for validation with cross validation\n",
    " - Hint: Search for good hyperparameters using the CAMELYON16 test set and the CAMELYON17 training set\n",
    "- Define and train a decision tree for predicting the CAMELYON17 training set\n",
    " - Hint1: Use `cross_val_predict`\n",
    " - Hint2: For optimal results always use the complete CAMELYON16 test set and all but one slide of the CAMELYON17 training set for training the classifier and only predict the one slide left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = None # Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`clf` is an instance of a trained decision tree classifier.\n",
    "\n",
    "The decision tree can be visualized. For this we must write a graphviz dot-File  \n",
    "\n",
    "It should look like:\n",
    "\n",
    "![internet connection needed](https://gitlab.com/deep.TEACHING/educational-materials/raw/master/media/klaus/medical-image-classification/dtree_render.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Source(tree.export_graphviz(clf, out_file=None\n",
    "   , feature_names=columns\n",
    "   , filled = True))\n",
    "graph\n",
    "\n",
    "### To open in seperate window and save it\n",
    "#graph.format = 'png'\n",
    "#graph.render('dtree_render',view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as CSV\n",
    "\n",
    "First prepare the DataFrame:\n",
    "- make a deep copy of `c17_train`\n",
    "- replace the stage values with you prediction\n",
    "- remove all collumns except the `patient` and `stage` column\n",
    "- save as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(names_preds))\n",
    "c17_train_copy = c17_train.copy(deep=True)\n",
    "print(c17_train_copy.loc[0].values[2])\n",
    "\n",
    "for i in range(500):\n",
    "    c17_train_copy.loc[i,'stage'] = names_preds[c17_train_copy.loc[i,'patient']]\n",
    "\n",
    "count = 0\n",
    "for i in range(500):\n",
    "    if c17_train_copy.loc[i].values[2] == c17_train.loc[i].values[2]:\n",
    "        count += 1\n",
    "        \n",
    "print(count / 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c17_train_copy = c17_train_copy.drop(c17_train_copy.columns[3:], axis=1)\n",
    "c17_train_copy = c17_train_copy.drop(c17_train_copy.columns[0], axis=1)\n",
    "c17_train_copy.to_csv(PATH_C17TRAIN_PREDICITONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Outlook\n",
    "\n",
    "Congratulations. If you worked through all notebooks from the beginning you just completed 99% of the complete CAMELYON challenge (16 and 17).\n",
    "\n",
    "If you want to improve your classifier, you can try to exchange the decision tree with another algorithm, e.g *naive bayes, support vector machine, random forest, etc...*. Depending on the classification algorithm you might also want to try out feature selection beforehand.\n",
    "\n",
    "\n",
    "\n",
    "In the next notebook you will determine the patient's pN stage based on your predictions for the slides, to finally calculate the kappa score and compare your results with others on the CAMELYON website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Licenses\n",
    "\n",
    "### Notebook License (CC-BY-SA 4.0)\n",
    "\n",
    "*The following license applies to the complete notebook, including code cells. It does however not apply to any referenced external media (e.g., images).*\n",
    "\n",
    "exercise-classify-heatmaps<br/>\n",
    "by Klaus Strohmenger<br/>\n",
    "is licensed under a [Creative Commons Attribution-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-sa/4.0/).<br/>\n",
    "Based on a work at https://gitlab.com/deep.TEACHING.\n",
    "\n",
    "\n",
    "### Code License (MIT)\n",
    "\n",
    "*The following license only applies to code cells of the notebook.*\n",
    "\n",
    "Copyright 2018 Klaus Strohmenger\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "deep_teaching_kernel",
   "language": "python",
   "name": "deep_teaching_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
