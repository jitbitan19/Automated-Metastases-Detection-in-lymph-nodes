{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATED_DATA = \"/storage/jitbitan/outputs/cam16_tiles/\"\n",
    "HDF5_FILE = GENERATED_DATA + \"all_wsi_tile256_poiNormal0.2_poiTumor0.6_level3.hdf5\"\n",
    "CHECKPOINT = \"/storage/jitbitan/outputs/inception_resnetv2_cam16.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal:\tslide count: 160 \n",
      "\ttile  count: 116147\n",
      "\n",
      "tumor:\tslide count: 73 \n",
      "\ttile  count: 15767\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(HDF5_FILE, \"r\") as f:\n",
    "    normal_tiles = 0\n",
    "    normal_slides = 0\n",
    "    tumor_tiles = 0\n",
    "    tumor_slides = 0\n",
    "\n",
    "    for key in f.keys():\n",
    "        x = f[key].shape[0]\n",
    "        if key.startswith(\"nor\"):\n",
    "            normal_tiles += x\n",
    "            normal_slides += 1\n",
    "        else:\n",
    "            tumor_tiles += x\n",
    "            tumor_slides += 1\n",
    "\n",
    "    print(f\"normal:\\tslide count: {normal_slides} \\n\\ttile  count: {normal_tiles}\\n\")\n",
    "    print(f\"tumor:\\tslide count: {tumor_slides} \\n\\ttile  count: {tumor_tiles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TissueDataset:\n",
    "    \"\"\"Data set for preprocessed WSIs of the CAMELYON16 and CAMELYON17 data set.\"\"\"\n",
    "\n",
    "    def __init__(self, path, p=0.5, first=True):\n",
    "        self.h5_file = path\n",
    "        self.h5 = h5py.File(path, \"r\", libver=\"latest\", swmr=True)\n",
    "        self.perc = p\n",
    "        self.first = first\n",
    "        self.dataset_names = list(self.h5.keys())\n",
    "        self.neg = [i for i in self.dataset_names if \"ormal\" in i]\n",
    "        self.pos = [i for i in self.dataset_names if \"umor\" in i]\n",
    "        self.dims = self.h5[self.neg[0]][0].shape\n",
    "\n",
    "    def __get_tiles_from_path(self, dataset_names, max_wsis, number_tiles):\n",
    "        tiles = np.ndarray((number_tiles, 256, 256, 3))\n",
    "        for i in range(number_tiles):\n",
    "            file_idx = np.random.randint(0, max_wsis)\n",
    "            dset = self.h5[dataset_names[file_idx]]\n",
    "            # dset = np.transpose(dset, (0,3,1,2))\n",
    "            len_ds = len(dset)\n",
    "            max_tiles = math.ceil(len_ds * self.perc)\n",
    "            if self.first:\n",
    "                rnd_idx = np.random.randint(0, max_tiles)\n",
    "            else:\n",
    "                rnd_idx = np.random.randint(len_ds - max_tiles, len_ds)\n",
    "            # crop random 256x256\n",
    "            if self.dims[1] > 256:\n",
    "                rand_height = np.random.randint(0, self.dims[0] - 256)\n",
    "                rand_width = np.random.randint(0, self.dims[1] - 256)\n",
    "            else:\n",
    "                rand_height = 0\n",
    "                rand_width = 0\n",
    "            tiles[i] = dset[\n",
    "                rnd_idx, rand_height : rand_height + 256, rand_width : rand_width + 256\n",
    "            ]\n",
    "        tiles = tiles / 255.0\n",
    "        return tiles\n",
    "\n",
    "    def __get_random_positive_tiles(self, number_tiles):\n",
    "        return self.__get_tiles_from_path(\n",
    "            self.pos, len(self.pos), number_tiles\n",
    "        ), np.ones((number_tiles))\n",
    "\n",
    "    def __get_random_negative_tiles(self, number_tiles):\n",
    "        return self.__get_tiles_from_path(\n",
    "            self.neg, len(self.neg), number_tiles\n",
    "        ), np.zeros((number_tiles))\n",
    "    \n",
    "    def batch_generator(self, num_neg=10, num_pos=10, data_augm=False, mean=[0.,0.,0.], std=[1.,1.,1.]):\n",
    "        while True:\n",
    "            x, y = self.get_batch(num_neg, num_pos, data_augm)\n",
    "            for i in [0,1,2]:\n",
    "                x[:,:,:,i] = (x[:,:,:,i] - mean[i]) / std[i]\n",
    "            yield x, y\n",
    "\n",
    "    def get_batch(\n",
    "        self,\n",
    "        num_neg=10,\n",
    "        num_pos=10,\n",
    "        data_augm=False,\n",
    "        mean=[0, 0, 0],\n",
    "        std=[1, 1, 1],\n",
    "    ):\n",
    "        x_p, y_p = self.__get_random_positive_tiles(num_pos)\n",
    "        x_n, y_n = self.__get_random_negative_tiles(num_neg)\n",
    "        x = np.concatenate((x_p, x_n), axis=0)\n",
    "        y = np.concatenate((y_p, y_n), axis=0)\n",
    "        if data_augm:\n",
    "            # some data augmentation mirroring / rotation\n",
    "            if np.random.randint(0, 2):\n",
    "                x = np.flip(x, axis=1)\n",
    "            if np.random.randint(0, 2):\n",
    "                x = np.flip(x, axis=2)\n",
    "            x = np.rot90(m=x, k=np.random.randint(0, 4), axes=(1, 2))\n",
    "\n",
    "        for i in range(3):\n",
    "            x[:, :, :, i] = (x[:, :, :, i] - mean[i]) / std[i]\n",
    "\n",
    "        # randomly arrange in order\n",
    "        p = np.random.permutation(len(y))\n",
    "        return np.transpose(x[p], (0, 3, 1, 2)), y[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pixel = np.full((3), 0.0)\n",
    "std_pixel = np.full((3), 1.0)\n",
    "\n",
    "# mean_channel = []\n",
    "# std_channel = []\n",
    "\n",
    "# with h5py.File(HDF5_FILE, \"r\") as f:\n",
    "#     all_keys = f.keys()\n",
    "#     for key in all_keys:\n",
    "#         data = f[key][:]\n",
    "#         mean_channel.append(np.mean(data, axis=(0, 1, 2)))\n",
    "#         std_channel.append(np.std(data, axis=(0, 1, 2)))\n",
    "\n",
    "# mean_channel_pixel = np.stack(mean_channel)\n",
    "# std_channel_pixel = np.stack(std_channel)\n",
    "\n",
    "# mean_pixel = np.mean(mean_channel_pixel, axis=0)\n",
    "# std_pixel = np.std(std_channel_pixel, axis=0)\n",
    "\n",
    "mean_pixel = np.array([189.83239041, 157.00127921, 188.64640922])\n",
    "std_pixel = np.array([10.63437092, 13.99272164, 12.21288545])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_session():\n",
    "    x = 5000\n",
    "\n",
    "    train_data = TissueDataset(path=HDF5_FILE, p=0.5, first=True)\n",
    "    val_data = TissueDataset(path=HDF5_FILE, p=0.5, first=False)\n",
    "\n",
    "    X_train, y_train = train_data.get_batch(\n",
    "        num_neg=x, num_pos=x, mean=mean_pixel, std=std_pixel, data_augm=True\n",
    "    )\n",
    "\n",
    "    X_val, y_val = val_data.get_batch(\n",
    "        num_neg=x // 2, num_pos=x // 2, mean=mean_pixel, std=std_pixel\n",
    "    )\n",
    "\n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    y_train_tensor = torch.LongTensor(y_train)\n",
    "\n",
    "    X_val_tensor = torch.FloatTensor(X_val)\n",
    "    y_val_tensor = torch.LongTensor(y_val)\n",
    "\n",
    "    dataset_train = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    dataset_test = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "    train_loader = DataLoader(dataset_train, batch_size=75, shuffle=True)\n",
    "    val_loader = DataLoader(dataset_test, batch_size=25, shuffle=True)\n",
    "\n",
    "    # Training\n",
    "\n",
    "    from inception_resnet_v2 import InceptionResNetV2\n",
    "    if torch.cuda.is_available():\n",
    "        inception = InceptionResNetV2().cuda()\n",
    "    else:\n",
    "        inception = InceptionResNetV2()\n",
    "    # inception = InceptionResNetV2()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimiser = torch.optim.Adam(inception.parameters(), lr=0.0001)\n",
    "\n",
    "    try:\n",
    "        inception.load_state_dict(torch.load(CHECKPOINT)[\"model_state_dict\"])\n",
    "        optimiser.load_state_dict(torch.load(CHECKPOINT)[\"optim_state_dict\"])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    n_train = X_train.shape[0]\n",
    "    n_val = X_val.shape[0]\n",
    "    e = 100\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracy = []\n",
    "    val_accuracy = []\n",
    "\n",
    "    for i in range(e):\n",
    "        t1 = datetime.now()\n",
    "\n",
    "        train_corr = 0\n",
    "        val_corr = 0\n",
    "\n",
    "        for X_train, y_train in train_loader:\n",
    "            X_train = X_train.to(\"cuda\")\n",
    "            y_train = y_train.to(\"cuda\")\n",
    "            y_pred = inception.forward(X_train)\n",
    "            loss = criterion(y_pred, y_train)\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "            predicted = torch.max(y_pred.data, 1)[1]\n",
    "            train_corr += (predicted == y_train).sum().item()\n",
    "\n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "        train_accuracy.append(train_corr * 100 / n_train)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in val_loader:\n",
    "                X_val = X_val.to(\"cuda\")\n",
    "                y_val = y_val.to(\"cuda\")\n",
    "                y_pred = inception.forward(X_val)\n",
    "                loss = criterion(y_pred, y_val)\n",
    "                val_losses.append(loss.item())\n",
    "\n",
    "                predicted = torch.max(y_pred.data, 1)[1]\n",
    "                val_corr += (predicted == y_val).sum().item()\n",
    "            val_accuracy.append(val_corr * 100 / n_val)\n",
    "\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_state_dict\": inception.state_dict,\n",
    "                \"optim_state_dict\": optimiser.state_dict,\n",
    "            },\n",
    "            CHECKPOINT,\n",
    "        )\n",
    "\n",
    "        t2 = datetime.now()\n",
    "        t = (t2 - t1).seconds\n",
    "\n",
    "        print(\n",
    "            f\"epoch: {i+1}\\ttrain loss: {train_losses[i]:.3f} \\ttrain accuracy: {train_accuracy[i]:2.3f}%\"\n",
    "        )\n",
    "        print(\n",
    "            f\"\\t\\tval loss:   {val_losses[i]:.3f} \\tval accuracy:   {val_accuracy[i]:2.3f}%\"\n",
    "        )\n",
    "        print(\n",
    "            f\"\\t\\tt/itr: {t}s\\t\\teta: {(e-i)*t/3600:.0f}hr {(((e-i)*t)%3600)/60:.0f}min\\n\"\n",
    "        )\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\ttrain loss: 0.700 \ttrain accuracy: 90.050%\n",
      "\t\tval loss:   0.394 \tval accuracy:   86.280%\n",
      "\t\tt/itr: 109s\t\teta: 3hr 2min\n",
      "\n",
      "epoch: 2\ttrain loss: 0.614 \ttrain accuracy: 93.180%\n",
      "\t\tval loss:   0.415 \tval accuracy:   89.100%\n",
      "\t\tt/itr: 103s\t\teta: 3hr 50min\n",
      "\n",
      "epoch: 3\ttrain loss: 0.559 \ttrain accuracy: 93.500%\n",
      "\t\tval loss:   0.513 \tval accuracy:   87.600%\n",
      "\t\tt/itr: 105s\t\teta: 3hr 52min\n",
      "\n",
      "epoch: 4\ttrain loss: 0.490 \ttrain accuracy: 94.920%\n",
      "\t\tval loss:   0.437 \tval accuracy:   89.200%\n",
      "\t\tt/itr: 104s\t\teta: 3hr 48min\n",
      "\n",
      "epoch: 5\ttrain loss: 0.499 \ttrain accuracy: 95.960%\n",
      "\t\tval loss:   0.442 \tval accuracy:   90.100%\n",
      "\t\tt/itr: 104s\t\teta: 3hr 46min\n",
      "\n",
      "epoch: 6\ttrain loss: 0.437 \ttrain accuracy: 96.060%\n",
      "\t\tval loss:   0.404 \tval accuracy:   89.700%\n",
      "\t\tt/itr: 104s\t\teta: 3hr 45min\n",
      "\n",
      "epoch: 7\ttrain loss: 0.402 \ttrain accuracy: 96.760%\n",
      "\t\tval loss:   0.441 \tval accuracy:   90.080%\n",
      "\t\tt/itr: 105s\t\teta: 3hr 44min\n",
      "\n",
      "epoch: 8\ttrain loss: 0.435 \ttrain accuracy: 96.510%\n",
      "\t\tval loss:   0.433 \tval accuracy:   90.320%\n",
      "\t\tt/itr: 104s\t\teta: 3hr 41min\n",
      "\n",
      "epoch: 9\ttrain loss: 0.430 \ttrain accuracy: 97.290%\n",
      "\t\tval loss:   0.422 \tval accuracy:   90.680%\n",
      "\t\tt/itr: 105s\t\teta: 3hr 41min\n",
      "\n",
      "epoch: 10\ttrain loss: 0.507 \ttrain accuracy: 97.540%\n",
      "\t\tval loss:   0.471 \tval accuracy:   91.780%\n",
      "\t\tt/itr: 104s\t\teta: 3hr 38min\n",
      "\n",
      "epoch: 11\ttrain loss: 0.440 \ttrain accuracy: 97.740%\n",
      "\t\tval loss:   0.463 \tval accuracy:   90.080%\n",
      "\t\tt/itr: 105s\t\teta: 3hr 38min\n",
      "\n",
      "epoch: 12\ttrain loss: 0.466 \ttrain accuracy: 97.480%\n",
      "\t\tval loss:   0.538 \tval accuracy:   90.980%\n",
      "\t\tt/itr: 104s\t\teta: 3hr 34min\n",
      "\n",
      "epoch: 13\ttrain loss: 0.429 \ttrain accuracy: 98.070%\n",
      "\t\tval loss:   0.354 \tval accuracy:   91.140%\n",
      "\t\tt/itr: 104s\t\teta: 3hr 33min\n",
      "\n",
      "epoch: 14\ttrain loss: 0.474 \ttrain accuracy: 98.310%\n",
      "\t\tval loss:   0.487 \tval accuracy:   91.400%\n",
      "\t\tt/itr: 105s\t\teta: 3hr 32min\n",
      "\n",
      "epoch: 15\ttrain loss: 0.438 \ttrain accuracy: 98.380%\n",
      "\t\tval loss:   0.444 \tval accuracy:   91.140%\n",
      "\t\tt/itr: 104s\t\teta: 2hr 29min\n",
      "\n",
      "epoch: 16\ttrain loss: 0.365 \ttrain accuracy: 98.290%\n",
      "\t\tval loss:   0.394 \tval accuracy:   89.840%\n",
      "\t\tt/itr: 105s\t\teta: 2hr 29min\n",
      "\n",
      "epoch: 17\ttrain loss: 0.422 \ttrain accuracy: 98.330%\n",
      "\t\tval loss:   0.373 \tval accuracy:   90.220%\n",
      "\t\tt/itr: 105s\t\teta: 2hr 27min\n",
      "\n",
      "epoch: 18\ttrain loss: 0.447 \ttrain accuracy: 97.900%\n",
      "\t\tval loss:   0.445 \tval accuracy:   90.820%\n",
      "\t\tt/itr: 105s\t\teta: 2hr 25min\n",
      "\n",
      "epoch: 19\ttrain loss: 0.450 \ttrain accuracy: 98.340%\n",
      "\t\tval loss:   0.554 \tval accuracy:   90.360%\n",
      "\t\tt/itr: 104s\t\teta: 2hr 22min\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with h5py.File(HDF5_FILE, \"r\") as f:\n",
    "#     normal_slides = []\n",
    "#     tumor_slides = []\n",
    "#     for key in f.keys():\n",
    "#         if key.startswith(\"nor\"):\n",
    "#             normal_slides.append(key)\n",
    "#         else:\n",
    "#             tumor_slides.append(key)\n",
    "\n",
    "#     normal_slides = np.array(normal_slides)\n",
    "#     tumor_slides = np.array(tumor_slides)\n",
    "\n",
    "#     np.random.shuffle(normal_slides)\n",
    "#     np.random.shuffle(tumor_slides)\n",
    "#     dummy = np.random.choice(\n",
    "#         tumor_slides, size=normal_slides.shape[0] - tumor_slides.shape[0]\n",
    "#     )\n",
    "#     tumor_slides = np.concatenate((tumor_slides, dummy), axis=0)\n",
    "#     for i in range(normal_slides.shape[0]):\n",
    "#         key1 = normal_slides[i]\n",
    "#         key2 = tumor_slides[i]\n",
    "\n",
    "#         normal_tiles = f[key1][:]\n",
    "#         tumor_tiles = f[key2][:]\n",
    "#         normal_labels = np.zeros(normal_tiles.shape[0])\n",
    "#         tumor_labels = np.ones(tumor_tiles.shape[0])\n",
    "\n",
    "#         all_tiles = np.concatenate((normal_tiles, tumor_tiles), axis=0)\n",
    "#         label = np.concatenate((normal_labels, tumor_labels), axis=0)\n",
    "#         n_tiles = all_tiles.shape[0]\n",
    "\n",
    "#         p = 0.7\n",
    "#         n_train = math.ceil(p * n_tiles)\n",
    "#         n_val = n_tiles - n_train\n",
    "\n",
    "#         np.random.shuffle(all_tiles)\n",
    "#         all_tiles = np.transpose(all_tiles, (0, 3, 1, 2))\n",
    "\n",
    "#         X_train = all_tiles[:n_train, :, :, :]\n",
    "#         y_train = label[:n_train]\n",
    "#         X_val = all_tiles[-n_val:, :, :, :]\n",
    "#         y_val = label[-n_val:]\n",
    "\n",
    "#         print(f\"Learning {key1} and {key2}, tile count: {n_tiles}\")\n",
    "#         learning_session(X_train, y_train, X_val, y_val, epoch=50, learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(16, 4), dpi=100)\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(train_losses)\n",
    "# plt.title(\"train loss\")\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(val_losses)\n",
    "# plt.title(\"val loss\")\n",
    "\n",
    "# plt.figure(figsize=(8, 4), dpi=100)\n",
    "# plt.plot(train_accuracy)\n",
    "# plt.plot(val_accuracy)\n",
    "# plt.legend([\"train accuracy\", \"val accuracy\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
